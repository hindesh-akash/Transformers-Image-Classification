{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import requests\n",
    "import json\n",
    "from io import BytesIO\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ObjectDetection:\n",
    "    COCO_INSTANCE_CATEGORY_NAMES = [\n",
    "        '__background__', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n",
    "        'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'N/A', 'stop sign',\n",
    "        'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
    "        'elephant', 'bear', 'zebra', 'giraffe', 'N/A', 'backpack', 'umbrella', 'N/A',\n",
    "        'N/A', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard',\n",
    "        'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard',\n",
    "        'surfboard', 'tennis racket', 'bottle', 'N/A', 'wine glass', 'cup', 'fork',\n",
    "        'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli',\n",
    "        'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant',\n",
    "        'bed', 'dining table', 'N/A', 'toilet', 'N/A', 'tv', 'laptop', 'mouse',\n",
    "        'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink',\n",
    "        'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier',\n",
    "        'toothbrush'\n",
    "    ]\n",
    "\n",
    "    def __init__(self, threshold=0.8):\n",
    "        self.threshold = threshold\n",
    "        self.model = models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "        self.model.eval()\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "\n",
    "    def load_image(self, image_path):\n",
    "        if image_path.startswith('http'):\n",
    "            response = requests.get(image_path)\n",
    "            img = Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
    "        else:\n",
    "            img = Image.open(image_path).convert(\"RGB\")\n",
    "        return img\n",
    "\n",
    "    def transform_image(self, image):\n",
    "        return self.transform(image)\n",
    "\n",
    "    def detect_objects(self, image_path):\n",
    "        # Load and transform the image\n",
    "        image = self.load_image(image_path)\n",
    "        # image = image_path\n",
    "        image_tensor = self.transform_image(image).unsqueeze(0)\n",
    "        \n",
    "        # Perform object detection\n",
    "        with torch.no_grad():\n",
    "            predictions = self.model(image_tensor)[0]\n",
    "        \n",
    "        # Parse the output and create the JSON structure\n",
    "        detected_objects = []\n",
    "        for label, score, box in zip(predictions['labels'], predictions['scores'], predictions['boxes']):\n",
    "            if score >= self.threshold:\n",
    "                try:\n",
    "                    name = self.COCO_INSTANCE_CATEGORY_NAMES[label.item()],\n",
    "                except:\n",
    "                    name = (\"others\",)\n",
    "                \n",
    "                \n",
    "                # print(type(name))\n",
    "                # print(name)\n",
    "                detected_objects.append({\n",
    "\n",
    "                    \"bb\": {\n",
    "                        \"topLeft\": {\n",
    "                            \"x\": box[0].item(),\n",
    "                            \"y\": box[1].item()\n",
    "                        },\n",
    "                        \"size\": {\n",
    "                            \"width\": (box[2] - box[0]).item(),\n",
    "                            \"height\": (box[3] - box[1]).item()\n",
    "                        }\n",
    "                    },\n",
    "                    \"name\" : name[0]\n",
    "                })\n",
    "\n",
    "        \n",
    "        if len(detected_objects) == 0:\n",
    "            return [\n",
    "                {\n",
    "                    \"bb\":{\n",
    "                        \"topLeft\":{\n",
    "                        \"x\":0,\n",
    "                        \"y\":0\n",
    "                        },\n",
    "                        \"size\":{\n",
    "                        \"width\":0,\n",
    "                        \"height\":0\n",
    "                        }\n",
    "                    },\n",
    "                    \"name\":\"None\"\n",
    "                }\n",
    "            ]\n",
    "        return detected_objects\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import VisionEncoderDecoderModel, ViTFeatureExtractor, AutoTokenizer\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "class ImageCaptioning:\n",
    "    def __init__(self):\n",
    "        self.model = VisionEncoderDecoderModel.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
    "        self.feature_extractor = ViTFeatureExtractor.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
    "\n",
    "    def generate_caption(self, image_path):\n",
    "        image = Image.open(image_path)\n",
    "        pixel_values = self.feature_extractor(images=image, return_tensors=\"pt\").pixel_values\n",
    "        output_ids = self.model.generate(pixel_values)\n",
    "        caption = self.tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "        return caption\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_detector = ObjectDetection()\n",
    "image_captioner = ImageCaptioning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_and_save_to_jsonl(images, output_file):\n",
    "        with open(output_file, 'w') as f:\n",
    "            for image in tqdm(images):\n",
    "\n",
    "                result = {}\n",
    "                objects = object_detector.detect_objects(image)\n",
    "                description = image_captioner.generate_caption(image)\n",
    "                result['objects'] = objects\n",
    "                result['description'] = description\n",
    "\n",
    "                f.write(json.dumps(result) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = 'E:\\\\Hackathons\\\\TopCoder\\\\AI-Powered Image Classification\\\\provisional\\\\provisional'\n",
    "images = os.listdir(image_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(images)):\n",
    "    images[i] = image_dir + \"\\\\\" + images[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [04:53<00:00,  7.33s/it]\n"
     ]
    }
   ],
   "source": [
    "output_path = \"E:\\\\Hackathons\\\\TopCoder\\\\AI-Powered Image Classification\\\\submission\\\\solution\\\\\"\n",
    "detect_and_save_to_jsonl(images, output_path+ 'submission.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
